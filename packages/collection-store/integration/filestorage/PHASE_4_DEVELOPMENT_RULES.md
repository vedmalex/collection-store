# üöÄ Phase 4: File Storage System - Development Rules

## üìã –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è Phase 4

### **–û—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ DEVELOPMENT_RULES.md —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π –¥–ª—è —Ñ–∞–π–ª–æ–≤–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è**

---

## üéØ –§–∞–∑–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ

### **Phase 4 —Ä–∞–∑–±–∏—Ç–∞ –Ω–∞ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

#### **Week 1: Core Foundation**
```markdown
## Week 1: Core File Storage Engine ‚úÖ
1. Unified File Storage Manager - —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π API
2. Storage Backend Abstraction - –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –∏ Local implementation
3. Streaming Support - chunked upload/download —Å progress tracking

–ü—Ä–∏–Ω—Ü–∏–ø –∏–∑–æ–ª—è—Ü–∏–∏: –∫–∞–∂–¥—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
```

#### **Week 2: Advanced Features**
```markdown
## Week 2: Advanced Features ‚úÖ
4. Thumbnail Generation Engine - image/video/document processing
5. File Replication Manager - cross-node distribution
6. Access Control Integration - permission-based file access

–ü—Ä–∏–Ω—Ü–∏–ø –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É—é—Ç—Å—è —á–µ—Ä–µ–∑ —á–µ—Ç–∫–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã
```

#### **Week 3: Integration & Testing**
```markdown
## Week 3: Integration & Testing ‚úÖ
7. Full Integration Testing - end-to-end scenarios
8. Performance Optimization - throughput –∏ latency optimization
9. Documentation & Examples - comprehensive usage guides

–ü—Ä–∏–Ω—Ü–∏–ø –≤–∞–ª–∏–¥–∞—Ü–∏–∏: –∫–∞–∂–¥—ã–π integration point —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
```

---

## üîß –ü—Ä–∞–≤–∏–ª–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è

### **1. Stream-First Architecture**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π streams –¥–ª—è —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
async function uploadFile(stream: ReadableStream, metadata: FileMetadata): Promise<void> {
  // –†–∞–±–æ—Ç–∞–µ–º —Å–æ stream –Ω–∞–ø—Ä—è–º—É—é, –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ –ø–∞–º—è—Ç—å
  const writeStream = fs.createWriteStream(filePath)
  await pipeline(stream, writeStream)
}

// ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –≤ –ø–∞–º—è—Ç—å
async function uploadFileBad(buffer: Buffer, metadata: FileMetadata): Promise<void> {
  // –ú–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å out of memory –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
  await fs.writeFile(filePath, buffer)
}

// –ü—Ä–∞–≤–∏–ª–æ: –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–π —Ñ–∞–π–ª—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤ –ø–∞–º—è—Ç—å
```

### **2. Backend Agnostic Design**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –ê–±—Å—Ç—Ä–∞–∫—Ü–∏—è storage backend
interface IStorageBackend {
  store(fileId: string, stream: ReadableStream): Promise<void>
  retrieve(fileId: string, range?: ByteRange): Promise<ReadableStream>
  delete(fileId: string): Promise<void>
}

class FileStorageManager {
  constructor(private backend: IStorageBackend) {}

  async upload(file: FileUpload): Promise<FileMetadata> {
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—é, –Ω–µ –∑–∞–≤–∏—Å–∏–º –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ backend
    await this.backend.store(fileId, file.stream)
  }
}

// ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û: –ü—Ä—è–º–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ backend
class FileStorageManagerBad {
  async upload(file: FileUpload): Promise<FileMetadata> {
    // –ñ–µ—Å—Ç–∫–æ –ø—Ä–∏–≤—è–∑–∞–Ω–æ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É —Ö—Ä–∞–Ω–µ–Ω–∏—é
    await fs.writeFile(localPath, file.buffer)
  }
}

// –ü—Ä–∞–≤–∏–ª–æ: –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ –¥–ª—è storage backends
```

### **3. Progress Tracking –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –¥–ª—è UX
class ChunkedUploader extends EventEmitter {
  async upload(stream: ReadableStream, totalSize: number): Promise<void> {
    let uploadedBytes = 0

    const progressStream = new TransformStream({
      transform(chunk, controller) {
        uploadedBytes += chunk.length

        // Emit progress events
        this.emit('progress', {
          uploadedBytes,
          totalSize,
          percentage: (uploadedBytes / totalSize) * 100
        })

        controller.enqueue(chunk)
      }
    })

    await pipeline(stream, progressStream, targetStream)
  }
}

// –ü—Ä–∞–≤–∏–ª–æ: –í—Å–µ–≥–¥–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π progress tracking –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–π >1MB
```

### **4. Robust Error Handling –¥–ª—è —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: Comprehensive error handling
async function uploadWithCleanup(file: FileUpload): Promise<FileMetadata> {
  let tempPath: string | null = null
  let metadata: FileMetadata | null = null

  try {
    // 1. Create temp file
    tempPath = await this.createTempFile()

    // 2. Upload to temp location
    await this.uploadToTemp(file.stream, tempPath)

    // 3. Validate file
    await this.validateFile(tempPath)

    // 4. Create metadata
    metadata = await this.createMetadata(file)

    // 5. Move to final location
    await this.moveToFinalLocation(tempPath, metadata.storagePath)

    // 6. Save metadata
    await this.saveMetadata(metadata)

    return metadata

  } catch (error) {
    // Cleanup on any error
    if (tempPath) {
      await this.cleanupTempFile(tempPath).catch(console.warn)
    }
    if (metadata) {
      await this.cleanupMetadata(metadata.id).catch(console.warn)
    }
    throw error
  }
}

// –ü—Ä–∞–≤–∏–ª–æ: –í—Å–µ–≥–¥–∞ –æ—á–∏—â–∞–π —Ä–µ—Å—É—Ä—Å—ã –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –≤ —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö
```

### **5. Checksum Validation**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –í–∞–ª–∏–¥–∞—Ü–∏—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤
async function uploadWithValidation(file: FileUpload): Promise<FileMetadata> {
  const expectedChecksum = file.checksum
  let calculatedChecksum: string

  // Calculate checksum during upload
  const hashStream = crypto.createHash('sha256')
  const progressStream = new PassThrough()

  progressStream.on('data', (chunk) => {
    hashStream.update(chunk)
  })

  await pipeline(file.stream, progressStream, targetStream)
  calculatedChecksum = hashStream.digest('hex')

  // Validate checksum
  if (expectedChecksum && expectedChecksum !== calculatedChecksum) {
    await this.cleanupFile(fileId) // Cleanup corrupted file
    throw new FileStorageError('Checksum validation failed', {
      expected: expectedChecksum,
      calculated: calculatedChecksum
    })
  }

  return { ...metadata, checksum: calculatedChecksum }
}

// –ü—Ä–∞–≤–∏–ª–æ: –í—Å–µ–≥–¥–∞ –≤–∞–ª–∏–¥–∏—Ä—É–π —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ checksum
```

---

## üß™ –ü—Ä–∞–≤–∏–ª–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Ñ–∞–π–ª–æ–≤–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è

### **6. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –¢–µ—Å—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ —Ñ–∞–π–ª–æ–≤
describe('File Upload Tests', () => {
  const testFiles = [
    { name: 'small.txt', size: 1024, type: 'text/plain' },
    { name: 'medium.jpg', size: 1024 * 1024, type: 'image/jpeg' },
    { name: 'large.mp4', size: 100 * 1024 * 1024, type: 'video/mp4' },
    { name: 'huge.zip', size: 1024 * 1024 * 1024, type: 'application/zip' }
  ]

  testFiles.forEach(testFile => {
    it(`should handle ${testFile.name} upload correctly`, async () => {
      const file = createTestFile(testFile.name, testFile.type, testFile.size)
      const metadata = await fileStorage.upload(file, options, user)

      expect(metadata.size).toBe(testFile.size)
      expect(metadata.mimeType).toBe(testFile.type)

      // Verify file can be downloaded
      const downloadStream = await fileStorage.download(metadata.id, {}, user)
      expect(downloadStream).toBeDefined()
    })
  })
})

// –ü—Ä–∞–≤–∏–ª–æ: –¢–µ—Å—Ç–∏—Ä—É–π —Å —Ñ–∞–π–ª–∞–º–∏ —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –∏ —Ç–∏–ø–æ–≤
```

### **7. Performance Testing –¥–ª—è —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –ò–∑–º–µ—Ä–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
describe('File Storage Performance', () => {
  it('should achieve target upload throughput', async () => {
    const fileSize = 50 * 1024 * 1024 // 50MB
    const file = createTestFile('performance.bin', 'application/octet-stream', fileSize)

    const startTime = performance.now()
    await fileStorage.upload(file, options, user)
    const duration = performance.now() - startTime

    const throughputMBps = (fileSize / (duration / 1000)) / (1024 * 1024)

    expect(throughputMBps).toBeGreaterThan(100) // >100MB/s target

    console.log(`Upload throughput: ${throughputMBps.toFixed(2)} MB/s`)
  })

  it('should handle concurrent uploads efficiently', async () => {
    const concurrentUploads = 10
    const files = Array.from({ length: concurrentUploads }, (_, i) =>
      createTestFile(`concurrent-${i}.jpg`, 'image/jpeg', 5 * 1024 * 1024)
    )

    const startTime = performance.now()

    const uploadPromises = files.map(file =>
      fileStorage.upload(file, options, user)
    )

    const results = await Promise.all(uploadPromises)
    const duration = performance.now() - startTime

    expect(results.length).toBe(concurrentUploads)
    expect(duration).toBeLessThan(30000) // Less than 30 seconds

    console.log(`Concurrent uploads completed in: ${duration.toFixed(2)}ms`)
  })
})

// –ü—Ä–∞–≤–∏–ª–æ: –í—Å–µ–≥–¥–∞ –∏–∑–º–µ—Ä—è–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
```

### **8. Memory Usage Testing**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –ö–æ–Ω—Ç—Ä–æ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
describe('Memory Usage Tests', () => {
  it('should not leak memory during large file operations', async () => {
    const initialMemory = process.memoryUsage().heapUsed

    // Upload large file
    const largeFile = createTestFile('memory-test.bin', 'application/octet-stream', 100 * 1024 * 1024)
    await fileStorage.upload(largeFile, options, user)

    // Force garbage collection
    if (global.gc) {
      global.gc()
    }

    const finalMemory = process.memoryUsage().heapUsed
    const memoryIncrease = finalMemory - initialMemory

    // Memory increase should be minimal (not proportional to file size)
    expect(memoryIncrease).toBeLessThan(10 * 1024 * 1024) // Less than 10MB

    console.log(`Memory increase: ${(memoryIncrease / 1024 / 1024).toFixed(2)} MB`)
  })
})

// –ü—Ä–∞–≤–∏–ª–æ: –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –±–æ–ª—å—à–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏
```

### **9. Error Recovery Testing**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ—à–∏–±–æ–∫
describe('Error Recovery Tests', () => {
  it('should cleanup partial uploads on stream error', async () => {
    const file = createTestFile('error-test.txt', 'text/plain', 1024)

    // Mock stream error
    const errorStream = new ReadableStream({
      start(controller) {
        controller.enqueue(new Uint8Array([1, 2, 3]))
        controller.error(new Error('Stream error'))
      }
    })

    file.stream = errorStream

    await expect(
      fileStorage.upload(file, options, user)
    ).rejects.toThrow('Stream error')

    // Verify no orphaned files or metadata
    const orphanedMetadata = await database.collection('file_metadata').find({
      filename: 'error-test.txt'
    })
    expect(orphanedMetadata.length).toBe(0)

    const orphanedFiles = await listOrphanedFiles()
    expect(orphanedFiles.length).toBe(0)
  })

  it('should handle backend unavailability gracefully', async () => {
    // Simulate backend failure
    const mockBackend = jest.spyOn(fileStorage['backendFactory'], 'getBackend')
    mockBackend.mockImplementation(() => {
      throw new Error('Backend unavailable')
    })

    const file = createTestFile('backend-error.txt', 'text/plain', 1024)

    await expect(
      fileStorage.upload(file, options, user)
    ).rejects.toThrow('Backend unavailable')

    // Verify graceful degradation
    expect(fileStorage.isHealthy()).toBe(false)

    mockBackend.mockRestore()
  })
})

// –ü—Ä–∞–≤–∏–ª–æ: –¢–µ—Å—Ç–∏—Ä—É–π –≤—Å–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –æ—à–∏–±–æ–∫ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
```

---

## üìä –ü—Ä–∞–≤–∏–ª–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### **10. Real-time Performance Metrics**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
class FileStoragePerformanceMonitor {
  private metrics = new Map<string, PerformanceMetric[]>()

  async measureFileOperation<T>(
    operation: string,
    fileSize: number,
    fn: () => Promise<T>
  ): Promise<T> {
    const startTime = performance.now()
    const startMemory = process.memoryUsage()

    try {
      const result = await fn()

      const duration = performance.now() - startTime
      const memoryDelta = process.memoryUsage().heapUsed - startMemory.heapUsed
      const throughputMBps = (fileSize / (duration / 1000)) / (1024 * 1024)

      this.recordMetric(operation, {
        duration,
        fileSize,
        throughputMBps,
        memoryDelta,
        success: true,
        timestamp: Date.now()
      })

      // Alert if performance degrades
      if (throughputMBps < this.getThresholds(operation).minThroughput) {
        this.alertPerformanceDegradation(operation, throughputMBps)
      }

      return result
    } catch (error) {
      this.recordMetric(operation, {
        duration: performance.now() - startTime,
        fileSize,
        success: false,
        error: error.message,
        timestamp: Date.now()
      })
      throw error
    }
  }

  getPerformanceStats(operation: string): PerformanceStats {
    const metrics = this.metrics.get(operation) || []
    const successfulMetrics = metrics.filter(m => m.success)

    return {
      totalOperations: metrics.length,
      successRate: successfulMetrics.length / metrics.length,
      averageThroughput: this.calculateAverage(successfulMetrics.map(m => m.throughputMBps)),
      p95Throughput: this.calculatePercentile(successfulMetrics.map(m => m.throughputMBps), 95),
      averageDuration: this.calculateAverage(successfulMetrics.map(m => m.duration)),
      p95Duration: this.calculatePercentile(successfulMetrics.map(m => m.duration), 95)
    }
  }
}

// –ü—Ä–∞–≤–∏–ª–æ: –ú–æ–Ω–∏—Ç–æ—Ä—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
```

---

## üîí –ü—Ä–∞–≤–∏–ª–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è

### **11. Access Control Validation**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —É—Ä–æ–≤–Ω–µ
async function downloadFile(fileId: string, user: User): Promise<ReadableStream> {
  // 1. Check if file exists
  const metadata = await this.getFileMetadata(fileId)
  if (!metadata) {
    throw new FileStorageError('File not found')
  }

  // 2. Check user permission
  const hasPermission = await this.authManager.checkDownloadPermission(user, metadata)
  if (!hasPermission) {
    await this.auditLogger.log({
      action: 'file_access_denied',
      userId: user.id,
      fileId,
      reason: 'insufficient_permissions'
    })
    throw new FileStorageError('Access denied')
  }

  // 3. Check file access level
  if (metadata.access === 'restricted') {
    const hasRestrictedAccess = await this.checkRestrictedAccess(user, metadata)
    if (!hasRestrictedAccess) {
      throw new FileStorageError('Restricted access denied')
    }
  }

  // 4. Log access
  await this.auditLogger.log({
    action: 'file_downloaded',
    userId: user.id,
    fileId,
    fileSize: metadata.size
  })

  return this.backend.retrieve(fileId)
}

// –ü—Ä–∞–≤–∏–ª–æ: –ü—Ä–æ–≤–µ—Ä—è–π –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
```

### **12. Secure File Validation**
```typescript
// ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –í–∞–ª–∏–¥–∞—Ü–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤
class FileSecurityValidator {
  async validateUpload(file: FileUpload, user: User): Promise<void> {
    // 1. Check file size limits
    if (file.size > this.getMaxFileSize(user)) {
      throw new FileStorageError('File size exceeds limit')
    }

    // 2. Check mime type restrictions
    if (!this.isAllowedMimeType(file.mimeType, user)) {
      throw new FileStorageError('File type not allowed')
    }

    // 3. Scan for malware (if enabled)
    if (this.config.malwareScanEnabled) {
      await this.scanForMalware(file.stream)
    }

    // 4. Check filename for security issues
    if (this.hasUnsafeFilename(file.filename)) {
      throw new FileStorageError('Unsafe filename detected')
    }

    // 5. Validate file content matches mime type
    const detectedMimeType = await this.detectMimeType(file.stream)
    if (detectedMimeType !== file.mimeType) {
      throw new FileStorageError('File content does not match declared type')
    }
  }

  private hasUnsafeFilename(filename: string): boolean {
    // Check for path traversal attempts
    if (filename.includes('..') || filename.includes('/') || filename.includes('\\')) {
      return true
    }

    // Check for executable extensions
    const dangerousExtensions = ['.exe', '.bat', '.cmd', '.scr', '.pif']
    return dangerousExtensions.some(ext => filename.toLowerCase().endsWith(ext))
  }
}

// –ü—Ä–∞–≤–∏–ª–æ: –í–∞–ª–∏–¥–∏—Ä—É–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –∑–∞–≥—Ä—É–∂–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
```

---

## üìã –ß–µ–∫-–ª–∏—Å—Ç –¥–ª—è Phase 4

### **–ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –∫–∞–∂–¥–æ–≥–æ –¥–Ω—è:**
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –≤—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–Ω—è –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –Ω–µ—Ç memory leaks –≤ —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- [ ] –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å integration points —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Ñ–∞–∑–∞–º–∏

### **–ü–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞:**
- [ ] –í—Å–µ unit —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] Performance —Ç–µ—Å—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ü–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- [ ] Memory usage —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] Error handling scenarios –ø–æ–∫—Ä—ã—Ç—ã
- [ ] Security validation —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞
- [ ] Audit logging –¥–æ–±–∞–≤–ª–µ–Ω–æ
- [ ] Documentation –æ–±–Ω–æ–≤–ª–µ–Ω–∞

### **–ü–µ—Ä–µ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º Phase 4:**
- [ ] –í—Å–µ 100+ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ—Ö–æ–¥—è—Ç (100% success rate)
- [ ] Performance benchmarks –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã
- [ ] Security requirements –≤—ã–ø–æ–ª–Ω–µ–Ω—ã
- [ ] Integration —Å Phases 1-3 —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] Documentation –ø–æ–ª–Ω–∞—è –∏ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è
- [ ] Examples —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã

---

## üéØ –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã Phase 4

### **1. Stream-First Architecture**
- –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–π —Ñ–∞–π–ª—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤ –ø–∞–º—è—Ç—å
- –ò—Å–ø–æ–ª—å–∑—É–π streams –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- –û–±–µ—Å–ø–µ—á–∏–≤–∞–π progress tracking –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤

### **2. Backend Agnostic Design**
- –ê–±—Å—Ç—Ä–∞–≥–∏—Ä—É–π storage backends —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π multiple backends –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
- –û–±–µ—Å–ø–µ—á–∏–≤–∞–π graceful degradation –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ backend

### **3. Security First**
- –í–∞–ª–∏–¥–∏—Ä—É–π –≤—Å–µ —Ñ–∞–π–ª–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
- –ü—Ä–æ–≤–µ—Ä—è–π –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —É—Ä–æ–≤–Ω–µ
- –õ–æ–≥–∏—Ä—É–π –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è audit trail

### **4. Performance Optimized**
- –î–æ—Å—Ç–∏–≥–∞–π —Ü–µ–ª–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- –ú–æ–Ω–∏—Ç–æ—Ä—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π –¥–ª—è concurrent operations

### **5. Error Recovery**
- –û—á–∏—â–∞–π —Ä–µ—Å—É—Ä—Å—ã –ø—Ä–∏ –ª—é–±—ã—Ö –æ—à–∏–±–∫–∞—Ö
- –û–±–µ—Å–ø–µ—á–∏–≤–∞–π graceful degradation
- –¢–µ—Å—Ç–∏—Ä—É–π –≤—Å–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è

---

**üèÜ PHASE 4: –ì–û–¢–û–í –ö –†–ï–ê–õ–ò–ó–ê–¶–ò–ò –° –ß–ï–¢–ö–ò–ú–ò –ü–†–ê–í–ò–õ–ê–ú–ò**

*–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è –≥–æ—Ç–æ–≤—ã –∫ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é*